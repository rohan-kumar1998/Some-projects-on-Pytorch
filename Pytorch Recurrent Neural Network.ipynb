{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torchvision.datasets as dsets \n",
    "import torchvision.transforms as transforms \n",
    "from torch.autograd import Variable\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dsets.MNIST(root = './data', train = True, transform = transforms.ToTensor(), download = False)\n",
    "test_dataset = dsets.MNIST(root = './data', train = False, transform= transforms.ToTensor(), download = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = 3000 \n",
    "batch_size = 100 \n",
    "num_epoch = n_iters/(len(train_dataset)/batch_size)\n",
    "num_epoch = int(num_epoch)\n",
    "train_loader = torch.utils.data.DataLoader(dataset= train_dataset,batch_size= batch_size, shuffle= True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size= batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNmodel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(RNNmodel,self).__init__()\n",
    "        self.hidden_dim = hidden_dim \n",
    "        self.layer_dim = layer_dim \n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first = True, nonlinearity = 'relu')\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = Variable(torch.zeros(self.layer_dim,x.size(0), self.hidden_dim))\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        out = self.fc(out[:,-1,:])\n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1 \n",
    "input_dim = 28 \n",
    "layer_dim = 1 \n",
    "hidden_dim = 100 \n",
    "output_dim = 10\n",
    "model = RNNmodel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr =learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations : 500, accuracy : 9\n",
      "iterations : 1000, accuracy : 9\n",
      "iterations : 1500, accuracy : 9\n",
      "iterations : 2000, accuracy : 9\n",
      "iterations : 2500, accuracy : 9\n",
      "iterations : 3000, accuracy : 9\n"
     ]
    }
   ],
   "source": [
    "seq_dim = 28 \n",
    "iters = 0\n",
    "for epoch in range(num_epoch):\n",
    "    for i,(images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images.view(-1,seq_dim, input_dim))\n",
    "        labels = Variable(labels)\n",
    "        optimizer.zero_grad() \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        iters += 1 \n",
    "        if iters%500 == 0:\n",
    "            total = 0 \n",
    "            correct = 0\n",
    "            for images, labels in train_loader:\n",
    "                images = Variable(images.view(-1,seq_dim,input_dim))\n",
    "                labels = Variable(labels)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                correct += (predicted == labels).sum()\n",
    "                total += labels.size(0)\n",
    "            accuracy = 100* correct/ total \n",
    "            print(\"iterations : {}, accuracy : {}\".format(iters,accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 0.8984208106994629. Accuracy: 67\n",
      "Iteration: 1000. Loss: 0.6864016056060791. Accuracy: 86\n",
      "Iteration: 1500. Loss: nan. Accuracy: 9\n",
      "Iteration: 2000. Loss: nan. Accuracy: 9\n",
      "Iteration: 2500. Loss: nan. Accuracy: 9\n",
      "Iteration: 3000. Loss: nan. Accuracy: 9\n"
     ]
    }
   ],
   "source": [
    "# Number of steps to unroll\n",
    "seq_dim = 28  \n",
    "\n",
    "iter = 0\n",
    "for epoch in range(num_epoch):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Load images as a tensor with gradient accumulation abilities\n",
    "        images = images.view(-1, seq_dim, input_dim).requires_grad_()\n",
    "        \n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass to get output/logits\n",
    "        # outputs.size() --> 100, 10\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                # Load images to a tensor with gradient accumulation abilities\n",
    "                images = images.view(-1, seq_dim, input_dim).requires_grad_()\n",
    "                \n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                \n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / total\n",
    "            \n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
